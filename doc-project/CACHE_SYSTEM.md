# üöÄ Sistema de Cache de Ativa√ß√£o - Documenta√ß√£o T√©cnica

## Vis√£o Geral

O **Cache de Ativa√ß√£o** √© uma otimiza√ß√£o cr√≠tica do AI Dev Superpowers que reduz drasticamente o consumo de tokens durante a inicializa√ß√£o de agentes IA em projetos de c√≥digo.

## O Problema Original

Quando um modelo de linguagem (LLM) √© ativado em um projeto, ele precisa entender:
- Quais agentes est√£o dispon√≠veis (Architect, Backend, QA, etc.)
- Quais skills podem ser executadas (TDD, Code Review, etc.)
- Qual √© o contexto do projeto (stack, fase, sprint)

**Sem cache**, o modelo precisa **ler cada arquivo individual**:

```
.aidev/
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.md     ‚Üê LLM l√™ (2000 tokens)
‚îÇ   ‚îú‚îÄ‚îÄ architect.md        ‚Üê LLM l√™ (1500 tokens)
‚îÇ   ‚îú‚îÄ‚îÄ backend.md          ‚Üê LLM l√™ (1200 tokens)
‚îÇ   ‚îú‚îÄ‚îÄ qa.md               ‚Üê LLM l√™ (1000 tokens)
‚îÇ   ‚îî‚îÄ‚îÄ ... (mais 5 agentes)
‚îú‚îÄ‚îÄ skills/
‚îÇ   ‚îú‚îÄ‚îÄ tdd/SKILL.md        ‚Üê LLM l√™ (800 tokens)
‚îÇ   ‚îú‚îÄ‚îÄ code-review/SKILL.md‚Üê LLM l√™ (600 tokens)
‚îÇ   ‚îî‚îÄ‚îÄ ... (mais 8 skills)
‚îî‚îÄ‚îÄ rules/
    ‚îî‚îÄ‚îÄ laravel.md          ‚Üê LLM l√™ (500 tokens)
```

**Resultado**: ~15.000+ tokens gastos apenas para "entender" o projeto.

---

## A Solu√ß√£o: Cache Pr√©-computado

O cache condensa **todas** as informa√ß√µes essenciais em um √∫nico JSON:

```json
{
  "version": "3.4.0",
  "generated_at": "2026-02-04T02:00:00-03:00",
  "project": {
    "stack": "livewire",
    "platform": "antigravity",
    "language": "php"
  },
  "agents": [
    {"name": "architect", "role": "Define arquitetura e decis√µes t√©cnicas"},
    {"name": "backend", "role": "Implementa l√≥gica de neg√≥cio e APIs"},
    {"name": "qa", "role": "Garante qualidade e cobertura de testes"}
  ],
  "skills": ["tdd", "code-review", "brainstorming", "debugging"],
  "rules": ["laravel", "generic"]
}
```

**Resultado**: ~500 tokens em vez de 15.000+.

---

## Fluxo T√©cnico

```mermaid
flowchart TD
    A[Usuario executa 'aidev agent'] --> B{Cache existe?}
    B -->|Sim| C[Valida hash do cache]
    C -->|V√°lido| D[Injeta JSON no prompt]
    C -->|Inv√°lido| E[Regenera cache]
    B -->|N√£o| E
    E --> D
    D --> F[Adiciona instru√ß√µes de economia]
    F --> G[Envia prompt final ao LLM]
    G --> H{Modelo obedece?}
    H -->|Claude| I[Ativa instantaneamente ‚úÖ]
    H -->|Gemini| J[Pode ignorar e ler arquivos ‚ö†Ô∏è]
    J --> K[Instru√ß√µes assertivas for√ßam economia]
```

---

## Implementa√ß√£o T√©cnica

### 1. Gera√ß√£o do Cache (`lib/cache.sh`)

```bash
generate_activation_cache() {
    local install_path="$1"
    local cache_file="$install_path/.aidev/cache/activation.json"
    
    # Coleta agentes com seus roles (extra√≠dos do ## Role de cada .md)
    for agent_file in "$install_path/.aidev/agents/"*.md; do
        local name=$(basename "$agent_file" .md)
        local role=$(grep -A 1 "## Role" "$agent_file" | tail -1 | head -c 200)
        agents+=("{\"name\": \"$name\", \"role\": \"$role\"}")
    done
    
    # Gera JSON compacto
    echo "{\"agents\": [$agents], \"skills\": [$skills]}" > "$cache_file"
}
```

### 2. Inje√ß√£o no Prompt (`bin/aidev`)

```bash
cmd_agent() {
    local cache_content=$(cat "$install_path/.aidev/cache/activation.json")
    
    if [ -n "$cache_content" ]; then
        echo "‚ö†Ô∏è CACHE DE ATIVA√á√ÉO DETECTADO (OBRIGAT√ìRIO) ‚ö†Ô∏è"
        echo '```json'
        echo "$cache_content"
        echo '```'
        echo "üõë PROIBIDO LER arquivos em .aidev/agents/ ou .aidev/skills/"
    fi
}
```

### 3. Valida√ß√£o de Integridade

O cache inclui um **hash SHA256** dos arquivos fonte. Se qualquer agente ou skill for modificado, o hash muda e o cache √© invalidado automaticamente:

```bash
validate_cache() {
    local stored_hash=$(jq -r '.hash' "$cache_file")
    local current_hash=$(compute_files_hash)
    
    [[ "$stored_hash" == "$current_hash" ]]
}
```

---

## Nuances Entre Modelos

| Aspecto | Claude | Gemini | GPT-4 |
|---------|--------|--------|-------|
| **Obedi√™ncia ao Cache** | ‚úÖ Excelente | ‚ö†Ô∏è Parcial | ‚úÖ Boa |
| **Leitura Desnecess√°ria** | Raro | Frequente | Ocasional |
| **Tempo de Ativa√ß√£o** | <1s | 5-10s | 2-3s |
| **Tokens na Ativa√ß√£o** | ~600 | ~3000+ | ~1200 |

### Por que o Gemini ignora instru√ß√µes?

O Gemini (especialmente via Antigravity) tende a ser **mais explorat√≥rio** e prefere verificar informa√ß√µes por conta pr√≥pria. Isso √© um padr√£o de comportamento do modelo, n√£o um bug.

**Solu√ß√£o implementada**: Instru√ß√µes ultra-assertivas com emojis de alerta (‚ö†Ô∏è üõë) e uso de termos como **"PROIBIDO"** e **"√öNICO"** que capturam a aten√ß√£o do modelo.

### Claude √© mais eficiente porque:

1. **Respeita hierarquias de instru√ß√£o** - Se o prompt diz "n√£o leia X", ele n√£o l√™.
2. **Otimiza automaticamente** - Detecta redund√¢ncia e evita a√ß√µes desnecess√°rias.
3. **Mant√©m contexto** - Lembra do cache entre turnos da conversa.

---

## Continuidade de Sess√£o

Al√©m do cache de ativa√ß√£o, o sistema tamb√©m injeta o **estado da sess√£o anterior**:

```bash
# L√™ estado do unified.json
active_intent=$(jq -r '.active_intent' "$unified_file")
active_skill=$(jq -r '.active_skill' "$unified_file")

# Injeta no prompt
echo "CONTEXTO ATUAL (SESS√ÉO ANTERIOR):"
echo "- Inten√ß√£o Ativa: $active_intent"
echo "- Skill em Uso: $active_skill"
echo "ATEN√á√ÉO: Continue o trabalho acima se n√£o estiver conclu√≠do."
```

Isso permite que o LLM **retome** uma tarefa anterior em vez de sugerir novas.

---

## Comandos Relevantes

| Comando | Descri√ß√£o |
|---------|-----------|
| `aidev cache --build` | Gera/regenera o cache manualmente |
| `aidev cache --status` | Mostra status e hash do cache |
| `aidev cache --clear` | Remove o cache (for√ßa leitura completa) |
| `aidev agent` | Gera prompt com cache injetado |

---

## M√©tricas de Economia

| Cen√°rio | Sem Cache | Com Cache | Economia |
|---------|-----------|-----------|----------|
| Primeira ativa√ß√£o | 15.000 tokens | 600 tokens | **96%** |
| Ativa√ß√£o subsequente | 15.000 tokens | 600 tokens | **96%** |
| Custo mensal (100 ativa√ß√µes/dia) | ~$45/m√™s | ~$2/m√™s | **$43/m√™s** |

---

## Arquitetura de Arquivos

```
.aidev/
‚îú‚îÄ‚îÄ cache/
‚îÇ   ‚îî‚îÄ‚îÄ activation.json     ‚Üê Cache pr√©-computado
‚îú‚îÄ‚îÄ state/
‚îÇ   ‚îú‚îÄ‚îÄ unified.json        ‚Üê Estado de sess√£o (intent, skill, checkpoints)
‚îÇ   ‚îî‚îÄ‚îÄ session.json        ‚Üê Estado legado (fase, sprint)
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.md     ‚Üê Agente principal (lido apenas se necess√°rio)
‚îÇ   ‚îî‚îÄ‚îÄ *.md                ‚Üê Outros agentes
‚îî‚îÄ‚îÄ skills/
    ‚îî‚îÄ‚îÄ */SKILL.md          ‚Üê Skills automatizadas
```

---

## Conclus√£o

O sistema de cache transforma a ativa√ß√£o de agentes IA de um processo **caro e lento** em uma opera√ß√£o **instant√¢nea e econ√¥mica**, adaptando-se √†s nuances de diferentes modelos de linguagem.

**Desenvolvido por**: AI Dev Superpowers v3.4.0
**√öltima atualiza√ß√£o**: 2026-02-04
